{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b9169a-ab2f-4f27-976c-c466e4abcd9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d90c131-a694-41c3-8867-1920ee01d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e065ebf-d595-4d31-b355-56befb5c28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages org.apache.hadoop:hadoop-aws:3.3.1 pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7759c5-2c70-40ad-b8d9-8398eff1c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar sparksession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Conexão_MinIO\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"ueVk36Brq2ZX8gCGGj1w\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"12345678\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://172.29.8.228:9000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf7baba-a721-4227-bbe6-c9c57968bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"c478634695f1e63e882ce6444d5198e4\"\n",
    "nome_cidade = [\"Aracaju\",\"Lagarto\",\"Itabaiana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da20ef76-6406-412a-8c89-948e3ace89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para convertar já que está puxando em kelvin.\n",
    "def kelvin_to_celsius(kelvin_temp):\n",
    "    return kelvin_temp - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36292694-17ce-41dd-a7dc-f633811376fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decidir definir um esquema\n",
    "schema = StructType([\n",
    "    StructField(\"city\", StringType(), True),  \n",
    "    StructField(\"temp\", DoubleType(), True),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1265fa46-8fe3-423b-a5e7-30a0e7621c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#puxar url\n",
    "dados_lista = []\n",
    "def get_data(city):\n",
    "    response = requests.get(f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Erro na obtenção dos dados para {city}: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f328083f-398c-4a22-b3d6-ccbee90ddd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#continuação\n",
    "for cidade in nome_cidade:\n",
    "    data = get_data(cidade)\n",
    "    if data:\n",
    "        dados_lista.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b4d3ae-ddbd-4b0a-9d37-da11bc96a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(dados_lista, schema)\n",
    "df = df.withColumn(\"temp\", F.format_number(df[\"temp\"], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa40946-5425-4638-a576-70b59d3e4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_path = \"s3a://desafiotempo\"\n",
    "df.write.format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"path\", f\"{bucket_path}/temperaturas.parquet\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10004b00-4296-4bdb-9495-768fb6846114",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
